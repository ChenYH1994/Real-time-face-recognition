{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從 攝影機 或 影片檔 去辨識人臉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    " \n",
    "def CatchUsbVideo(window_name, camera_idx):\n",
    "    cv2.namedWindow(window_name)\n",
    "    \n",
    "    # 影像來源\n",
    "    cap = cv2.VideoCapture(camera_idx)                \n",
    "    \n",
    "    # keras 提供的人臉辨識器\n",
    "    classfier = cv2.CascadeClassifier(r\"C:\\Users\\user\\PycharmProjects\\TensorFlow-Keras\\OpenCV\\haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "    # 人臉框的顏色\n",
    "    color = (0, 255, 0)\n",
    "        \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        #讀取一幀影像\n",
    "        ok, frame = cap.read() \n",
    "        if not ok:            \n",
    "            break  \n",
    " \n",
    "        # RGB 轉成 灰階圖減低運算\n",
    "        grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                 \n",
    "        \n",
    "        # 人臉檢測\n",
    "        faceRects = classfier.detectMultiScale(grey, scaleFactor = 1.2, minNeighbors = 4, minSize = (32, 32))\n",
    "        \n",
    "        # len(faceRects) 表示偵測到的人臉數\n",
    "        if len(faceRects) > 0:     \n",
    "            \n",
    "            # 每張人臉的位置\n",
    "            for faceRect in faceRects:\n",
    "                \n",
    "                # 左上角座標 (x, y)、寬高 (w,h)\n",
    "                x, y, w, h = faceRect  \n",
    "                \n",
    "                # 框出人臉\n",
    "                cv2.rectangle(frame, (x , y), (x + w , y + h), color, 2)\n",
    "                        \n",
    "        # 顯示畫面\n",
    "        cv2.imshow(window_name, frame)        \n",
    "        c = cv2.waitKey(10)\n",
    "        if c & 0xFF == ord('q'):\n",
    "            break        \n",
    "    \n",
    "    # 關閉顯示框 \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    \n",
    "CatchUsbVideo(\"FACE\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對影片中的每幀畫面做擷取圖像並儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import matlibplot.pyplot as plt\n",
    "%matlibplot inline\n",
    "\n",
    "def CatchUsbVideo(window_name, camera_idx, catch_pic_num, path_name):\n",
    "    \n",
    "    cv2.namedWindow(window_name)\n",
    "    \n",
    "    cap = cv2.VideoCapture(camera_idx)                \n",
    "    \n",
    "    classfier = cv2.CascadeClassifier(r\"C:\\Users\\user\\PycharmProjects\\TensorFlow-Keras\\OpenCV\\haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "    color = (0, 255, 0)\n",
    "        \n",
    "    num=0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ok, frame = cap.read() \n",
    "        if not ok:            \n",
    "            break  \n",
    "\n",
    "        grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                 \n",
    "        \n",
    "        faceRects = classfier.detectMultiScale(grey, scaleFactor = 1.2, minNeighbors = 3, minSize = (32, 32))\n",
    "\n",
    "        if len(faceRects) > 0: \n",
    "                                   \n",
    "            for faceRect in faceRects:\n",
    "                \n",
    "                x, y, w, h = faceRect \n",
    "                \n",
    "                # 將當前畫面儲存為 JPG 圖片檔\n",
    "                # %s 是路徑， %d 是號碼\n",
    "                img_name = '%s/%d.jpg'%(path_name, num)   \n",
    "                \n",
    "                # 框出人臉位置存入變數 image\n",
    "                image = frame[y - 10: y + h + 10, x - 10: x + w + 10]\n",
    "                \n",
    "                # 儲存\n",
    "                cv2.imwrite(img_name, image)                                \n",
    "                                \n",
    "                num += 1  \n",
    "                \n",
    "                # 超過擷取數量便停止擷取\n",
    "                if num > (catch_pic_num):   \n",
    "                    break\n",
    "                \n",
    "                # 擷取時畫面的人臉框\n",
    "                cv2.rectangle(frame, (x - 10, y - 10), (x + w + 10, y + h + 10), color, 2)\n",
    "                \n",
    "                # 在框上顯示目前擷取的數量\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(frame,'num:%d'%(num),(x+30,y+30),font,1,(255,0,225),4)\n",
    "                \n",
    "                        \n",
    "        \n",
    "        cv2.imshow(window_name, frame)\n",
    "#         plt.imshow(window_name, frame)    \n",
    "#         plt.show()    \n",
    "        c = cv2.waitKey(10)\n",
    "    \n",
    "        if c & 0xFF == ord('q'):\n",
    "            break        \n",
    "    \n",
    "   \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    \n",
    "    \n",
    "# 儲存路徑\n",
    "PATH = r\"C:\\\\Users\\\\user\\\\PycharmProjects\\\\TensorFlow-Keras\\\\OpenCV\\\\data\\\\Mother\"\n",
    "\n",
    "# 將儲存路徑 PATH 代入擷取函數 CatchUsbVideo，擷取 1000 多張\n",
    "CatchUsbVideo(\"CUT_face\",0,1000,PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尺寸調整函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "#按照指定影象大小調整尺寸\n",
    "def resize_image(image, height = IMAGE_SIZE, width = IMAGE_SIZE):\n",
    "    \n",
    "    top, bottom, left, right = (0, 0, 0, 0)\n",
    "    \n",
    "    #獲取影象尺寸\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    #對於長寬不相等的圖片，找到最長的一邊\n",
    "    longest_edge = max(h, w)    \n",
    "    \n",
    "    #計算短邊需要增加多上畫素寬度使其與長邊等長\n",
    "    if h < longest_edge:\n",
    "        dh = longest_edge - h\n",
    "        top = dh // 2\n",
    "        bottom = dh - top\n",
    "    elif w < longest_edge:\n",
    "        dw = longest_edge - w\n",
    "        left = dw // 2\n",
    "        right = dw - left\n",
    "    else:\n",
    "        pass \n",
    "    \n",
    "    #RGB顏色\n",
    "    BLACK = [0, 0, 0]\n",
    "    \n",
    "    #給影象增加邊界，是圖片長、寬等長，cv2.BORDER_CONSTANT指定邊界顏色由value指定\n",
    "    constant = cv2.copyMakeBorder(image, top , bottom, left, right, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    \n",
    "    #調整影象大小並返回\n",
    "    return cv2.resize(constant, (height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用 VGG16 訓練分類模型 ( 在 Colab 訓練 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# 載入 keras 內建好的 vgg16 模型\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "\n",
    "# 標註標籤用\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# 劃分訓練集、測試集用\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 評分用\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 載入 VggNet，去除全連接層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 圖片處理函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelProcess(img_path, model):\n",
    "    \n",
    "    # 讀取圖片，轉成 224 x 224 大小 \n",
    "    img = load_img(img_path, target_size=(224, 224)) \n",
    "\n",
    "    # 把numpy矩陣中的整數轉換成浮點數，以便於正規化 ./255 的計算\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # 多加一個維度載入 VGG \n",
    "    x = np.expand_dims(img, axis=0) \n",
    "\n",
    "    # 加載單個圖像時，將獲得一個圖像的形狀，即 (size1,size2,channels)\n",
    "    # 為了創建一批圖像，您需要一個附加的維度 : (samples, size1,size2, channels)\n",
    "    # preprocess_input 函數旨在使圖像適合模型所需的格式\n",
    "    # 正規化\n",
    "    x = preprocess_input(x) \n",
    "\n",
    "    # 特徵提取，全連接層之前的動作\n",
    "    x_vgg = model.predict(x) \n",
    "\n",
    "    # shape（1,7,7,512）\n",
    "    # 攤平準備掛接全連接層\n",
    "    x_vgg = x_vgg.reshape(1, 25088) \n",
    "\n",
    "    return x_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 從資料夾讀取影像資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    \n",
    "    folders = os.listdir(path)             # 讀取訓練集內的所有類別資料夾\n",
    "    for j in range(len(folders)):          # 總共 3 類\n",
    "        folder = path + '/' + folders[j]   # 各類資料夾的路徑\n",
    "        dirs = os.listdir(folder)          # 每類的圖片路徑\n",
    "        \n",
    "        # 所有圖片路徑列表\n",
    "        img_path = []\n",
    "        for i in dirs:\n",
    "            if os.path.splitext(i)[1] == \".jpg\": \n",
    "                img_path.append(i)\n",
    "                \n",
    "        # 絕對路徑\n",
    "        img_path = [folder + \"/\" + i for i in img_path] \n",
    "        \n",
    "        \n",
    "        # 訓練圖片處理\n",
    "        # 定義待儲存的 list\n",
    "        features1 = np.zeros([len(img_path), 25088]) \n",
    "        \n",
    "        for i in range(len(img_path)):\n",
    "            \n",
    "            # 對每張圖片進行處理及特徵提取\n",
    "            feature_i = modelProcess(img_path[i], model_vgg) \n",
    "            \n",
    "            # 印出每張圖的路徑\n",
    "            print('preprocessed:', img_path[i])\n",
    "            \n",
    "            # 圖像資料儲存\n",
    "            features1[i] = feature_i\n",
    "        \n",
    "        # 將所有處理後並攤平的圖像資料放入 X\n",
    "        if j == 0: \n",
    "            X = features1 \n",
    "        else:\n",
    "            X = np.concatenate((X, features1), axis=0)\n",
    "            \n",
    "    return X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 標籤函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label(path):\n",
    "    y = []\n",
    "    folders = os.listdir(path)                   # 訓練集路徑\n",
    "    for j in range(len(folders)): \n",
    "        dirName = path + '/' + folders[j] + '/'  # 各類路徑\n",
    "        lens = len(os.listdir(dirName))          # 每類的圖片數量\n",
    "        for i in range(lens):\n",
    "            y.append(j)                          # 有多少張圖，就給多少標籤; 注意，這裡是給 j \n",
    "    lb = LabelBinarizer() \n",
    "    y = lb.fit_transform(y)                      # ONE_HOT\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/Colab Notebooks/DATA' # 訓練集的資料夾路徑\n",
    "\n",
    "y = read_label(path)                                 # 上標籤\n",
    "\n",
    "X = read_data(path)                                  # 依照印出的先後知道各類的標籤碼為何"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 劃分訓練集、驗證集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=50)\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搭建全連接層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "model = Sequential()\n",
    "\n",
    "# 輸入維度是 25088\n",
    "model.add(Dense(units=40, activation='relu', input_dim=25088))\n",
    "\n",
    "# 我們分三類 ( 2 類以上 )，用 softmax ; 若是二分類，用 sigmoid\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# 查看結構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練器是 Adam，二分類用 binary_crossentropy，評估指標用準確率 accuracy\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# 訓練\n",
    "model.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('Eric_Chen_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 即時人臉偵測及分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a3321f0ea8ea>:69: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-a3321f0ea8ea>:72: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "\n",
    "# 載入vgg模型，去除全連接層\n",
    "model_vgg = VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "# 載入全連接層分類模型\n",
    "model = load_model(r\"C:\\Users\\user\\PycharmProjects\\TensorFlow-Keras\\OpenCV\\Eric_Chen_3.h5\")    \n",
    "              \n",
    "# 框住人臉的矩形邊框顏色       \n",
    "color = (0, 255, 0)\n",
    "    \n",
    "# 抓取攝像機的畫面資料\n",
    "cap = cv2.VideoCapture(0)\n",
    "    \n",
    "# 人臉識別分類器儲存路徑\n",
    "cascade_path = r\"C:\\Users\\user\\PycharmProjects\\TensorFlow-Keras\\OpenCV\\haarcascade_frontalface_default.xml\" \n",
    "    \n",
    "# 迴圈檢測識別人臉\n",
    "while True:\n",
    "    \n",
    "        # 每偵畫面\n",
    "        ret, frame = cap.read()   \n",
    "        \n",
    "#         if ret is True:\n",
    "            \n",
    "#             #影象灰化，降低計算複雜度\n",
    "#             frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         else:\n",
    "#             continue\n",
    "            \n",
    "        #使用人臉識別分類器，讀入分類器\n",
    "        cascade = cv2.CascadeClassifier(cascade_path)                \n",
    "\n",
    "        #利用分類器識別出哪個區域為人臉\n",
    "        faceRects = cascade.detectMultiScale(frame, scaleFactor = 1.2, minNeighbors = 3, minSize = (32, 32))        \n",
    "        if len(faceRects) > 0:                 \n",
    "            for faceRect in faceRects: \n",
    "                x, y, w, h = faceRect\n",
    "                \n",
    "                # 擷取臉部影象提交給模型識別這是誰 \n",
    "                # 左上角(x、y） 以及 長、寬（h、w)\n",
    "                image = frame[y - 10: y + h + 10, x - 10: x + w + 10]\n",
    "        \n",
    "                # resize\n",
    "                image = resize_image(image)\n",
    "                    \n",
    "#                 #浮點並歸一化\n",
    "#                 image = image.astype('float32')\n",
    "#                 image /= 255\n",
    "                \n",
    "                image = img_to_array(image)\n",
    "                xg = np.expand_dims(image, axis=0)\n",
    "                xg = preprocess_input(xg)\n",
    "                x_vgg = model_vgg.predict(xg)\n",
    "                x_vgg = x_vgg.reshape(1, 25088)\n",
    "\n",
    "                \n",
    "                #給出輸入屬於各個類別的概率，我們是二值類別，則該函式會給出輸入影象屬於 0 和 1 的概率各為多少\n",
    "                result1 = model.predict_proba(x_vgg)\n",
    "                \n",
    "                # 給出類別預測：0 或者 1\n",
    "                result = model.predict_classes(x_vgg)\n",
    "            \n",
    "                # 辨識出的類別\n",
    "                faceID = result[0]\n",
    "                \n",
    "                x1=int(x - 5)\n",
    "                x2=int(y - 5)\n",
    "                y1=int(x + w + 5)\n",
    "                y2=int(y + h + 5)\n",
    "                \n",
    "                #如果是 \" 我 \"\n",
    "                if faceID == 2:                                                        \n",
    "                    cv2.rectangle(frame, (x1, x2), (y1, y2), color, thickness = 2)\n",
    "                    \n",
    "                    #文字提示是誰\n",
    "                    cv2.putText(frame,\"ME\", \n",
    "                                (x + 30, y + 30),                      #座標\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,              #字型\n",
    "                                1,                                     #字號\n",
    "                                (255,0,255),                           #顏色\n",
    "                                2)                                     #字的線寬\n",
    "                    \n",
    "                # 如果是 \" 爸爸 \"   \n",
    "                elif faceID == 1:                                                        \n",
    "                    cv2.rectangle(frame, (x1, x2), (y1, y2), color, thickness = 2)\n",
    "                    \n",
    "                    \n",
    "                    cv2.putText(frame,\"Fther\", \n",
    "                                (x + 30, y + 30),                      \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,              \n",
    "                                1,                                     \n",
    "                                (255,0,255),                           \n",
    "                                2)                                     \n",
    "                \n",
    "                # 如果是 \" 媽媽 \"\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x1, x2), (y1, y2), color, thickness = 2)\n",
    "                    \n",
    "                    \n",
    "                    cv2.putText(frame,\"Mother\", \n",
    "                                (x + 30, y + 30),                      \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,              \n",
    "                                1,                                     \n",
    "                                (255,0,255),                           \n",
    "                                2)                                     \n",
    "                    \n",
    "                            \n",
    "        cv2.imshow(\"Family\", frame)\n",
    "        \n",
    "        k = cv2.waitKey(1)\n",
    "        \n",
    "        if k & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
